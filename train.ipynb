{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "from HydraSalsa import HydraSalsa\n",
    "sys.path.append('/ari/users/ibaskaya/projeler/hydrasalsa/utils')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "from scipy.ndimage import convolve\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ari/users/ibaskaya/.conda/envs/waymo/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from fastfill import FastFill\n",
    "from scale3d import RandomRescaleRangeImage\n",
    "from dskittiwaymo import SegmentationDataset\n",
    "from combinedloader import MixedDataLoader\n",
    "\n",
    "from metric_miou import calculate_classwise_intersection_union,calculate_final_miou_from_batches, calculate_miou\n",
    "from printiou import print_miou_kitti, print_miou_waymo\n",
    "from lovasz import Lovasz_softmax\n",
    "\n",
    "from mappings import kitti_normalized_frequencies, waymovalidfreqs\n",
    "\n",
    "num_classes_kitti = 20\n",
    "num_classes_waymo = 23\n",
    "inchannels = 5\n",
    "\n",
    "frequencies = kitti_normalized_frequencies\n",
    "frequencies_waymo = [i/sum(waymovalidfreqs) for i in waymovalidfreqs]\n",
    "max_epochs = 150               # number of epochs\n",
    "learning_rate = 0.01           # initial learning rate for SGD\n",
    "warmup_epochs = 1              # number of warmup epochs\n",
    "momentum = 0.9                 # momentum for SGD\n",
    "lr_decay = 0.99                # learning rate decay factor per epoch\n",
    "weight_decay = 0.0001          # weight decay for optimizer\n",
    "batch_size = 8                # batch size\n",
    "epsilon_w = 0.001 \n",
    "\n",
    "\n",
    "model = HydraSalsa([num_classes_kitti,num_classes_waymo],inchannels)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "print(device, ' is used')\n",
    "\n",
    "ffk = FastFill(tofill=0, indices=[0,1,2,3,4])\n",
    "ffw = FastFill(tofill=-1, indices=[0,1,2,3,4])\n",
    "transform_train = A.Compose([\n",
    "    A.Resize(height=64, width=2048, interpolation=cv2.INTER_NEAREST, p=1),  # Resize\n",
    "    A.ShiftScaleRotate(shift_limit=0.5, scale_limit=0.0, rotate_limit=0, \n",
    "                       border_mode=cv2.BORDER_WRAP, interpolation=cv2.INTER_NEAREST,\n",
    "                       p=0.5),  \n",
    "    A.RandomCrop(height = 64, width = 2048, p=1),\n",
    "    #A.PadIfNeeded(min_height=64, min_width=2048, border_mode=0, value=0, mask_value=0),\n",
    "    A.HorizontalFlip(p=0.5),  # Horizontal flip with 20% probability\n",
    "    #A.CoarseDropout(max_holes=2, max_height=64, max_width=256, min_holes=1, min_height=1, min_width=1, fill_value=0, p=1),  # CoarseDropout instead of Cutout\n",
    "    ToTensorV2()  # Convert to PyTorch tensors\n",
    "], additional_targets={'mask': 'image'})\n",
    "transform_valid = A.Compose([\n",
    "    A.Resize(height=64, width=2048, interpolation=cv2.INTER_NEAREST, p=1),  # Resize\n",
    "    #A.RandomCrop(height = 64, width = 2048, p=1),\n",
    "    #A.PadIfNeeded(min_height=64, min_width=2048, border_mode=0, value=0, mask_value=0),\n",
    "    #A.HorizontalFlip(p=0.5),  # Horizontal flip with 20% probability\n",
    "    #A.CoarseDropout(max_holes=2, max_height=64, max_width=256, min_holes=1, min_height=1, min_width=1, fill_value=0, p=1),  # CoarseDropout instead of Cutout\n",
    "    ToTensorV2()  # Convert to PyTorch tensors\n",
    "], additional_targets={'mask': 'image'})\n",
    "#pretransform = RandomRescaleRangeImage(p=1)\n",
    "pretransform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Kitti\n",
    "train_dataset = SegmentationDataset(root = '/ari/users/ibaskaya/projeler/hydrasalsa/data/kitti', \n",
    "                                    split = 'training', transform=transform_train, \n",
    "                                    pretransform=pretransform, fastfill=ffk, iswaymo=False, width=2048)\n",
    "\n",
    "ktrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "validation_dataset = SegmentationDataset(root = '/ari/users/ibaskaya/projeler/hydrasalsa/data/kitti', \n",
    "                                    split = 'validation', transform=transform_valid, \n",
    "                                    pretransform=None, fastfill=ffk, iswaymo=False, width=2048)\n",
    "kvalidation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=2)\n",
    "\n",
    "##Waymo\n",
    "wtrain_dataset = SegmentationDataset(root = '/ari/users/ibaskaya/projeler/hydrasalsa/data/waymo', \n",
    "                                    split = 'training', transform=transform_train, \n",
    "                                    pretransform=pretransform, fastfill=ffw, iswaymo=True, width=2650,unknown=-1)\n",
    "\n",
    "wtrain_dataloader = torch.utils.data.DataLoader(wtrain_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "wvalidation_dataset = SegmentationDataset(root = '/ari/users/ibaskaya/projeler/hydrasalsa/data/waymo', \n",
    "                                    split = 'validation', transform=transform_valid, \n",
    "                                    pretransform=None, fastfill=ffk, iswaymo=True, width=2650,unknown=-1)\n",
    "wvalidation_dataloader = torch.utils.data.DataLoader(wvalidation_dataset, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=2)\n",
    "\n",
    "#Mixed Loader\n",
    "train_dataloader = MixedDataLoader(ktrain_dataloader,wtrain_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ari/users/ibaskaya/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "  0%|          | 0/2391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2391 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/42], Training Loss: 0.0017, LR: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################KITTI_START########################\n",
      "Classwise IoU:\n",
      "  car: 0.0000\n",
      "  bicycle: 0.0000\n",
      "  motorcycle: 0.0000\n",
      "  truck: 0.0000\n",
      "  other-vehicle: 0.0000\n",
      "  person: 0.0000\n",
      "  bicyclist: 0.0000\n",
      "  motorcyclist: 0.0000\n",
      "  road: 0.0000\n",
      "  parking: 0.0000\n",
      "  sidewalk: 0.0000\n",
      "  other-ground: 0.0000\n",
      "  building: 0.0000\n",
      "  fence: 0.0000\n",
      "  vegetation: 0.0000\n",
      "  trunk: 0.0073\n",
      "  terrain: 0.0000\n",
      "  pole: 0.0000\n",
      "  traffic-sign: 0.0000\n",
      "\n",
      "Mean IoU: 0.0004\n",
      "Total IoU: 0.0036\n",
      "Epoch [1/42], Validation mIoU Kitti: 0.0006\n",
      "###################KITTI_END##########################\n",
      "###################WAYMO_START########################\n",
      "Classwise IoU:\n",
      "  TYPE_CAR: 0.0000\n",
      "  TYPE_TRUCK: 0.0000\n",
      "  TYPE_BUS: 0.0000\n",
      "  TYPE_OTHER_VEHICLE: 0.0000\n",
      "  TYPE_MOTORCYCLIST: 0.0000\n",
      "  TYPE_BICYCLIST: 0.0000\n",
      "  TYPE_PEDESTRIAN: 0.0000\n",
      "  TYPE_SIGN: 0.0454\n",
      "  TYPE_TRAFFIC_LIGHT: 0.0000\n",
      "  TYPE_POLE: 0.0000\n",
      "  TYPE_CONSTRUCTION_CONE: 0.0000\n",
      "  TYPE_BICYCLE: 0.0000\n",
      "  TYPE_MOTORCYCLE: 0.0000\n",
      "  TYPE_BUILDING: 0.0000\n",
      "  TYPE_VEGETATION: 0.0000\n",
      "  TYPE_TREE_TRUNK: 0.0000\n",
      "  TYPE_CURB: 0.0000\n",
      "  TYPE_ROAD: 0.1916\n",
      "  TYPE_LANE_MARKER: 0.0000\n",
      "  TYPE_OTHER_GROUND: 0.0000\n",
      "  TYPE_WALKABLE: 0.0000\n",
      "  TYPE_SIDEWALK: 0.0000\n",
      "\n",
      "Mean IoU: 0.0108\n",
      "Total IoU: 0.1040\n",
      "Epoch [1/42], Validation mIoU Waymo: 0.0169\n",
      "###################WAYMO_END##########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/42], Training Loss: 0.0017, LR: 0.009900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 90\u001b[0m\n\u001b[1;32m     87\u001b[0m batch_results_kitti, batch_results_waymo \u001b[38;5;241m=\u001b[39m [], [] \n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkvalidation_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Forward pass and predictions\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/waymo/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/.conda/envs/waymo/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/waymo/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/.conda/envs/waymo/lib/python3.12/multiprocessing/connection.py:1136\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/.conda/envs/waymo/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "inverse_frequencies = [1.0 / (f + epsilon_w) for f in frequencies]\n",
    "inverse_frequencies[0] = min(inverse_frequencies) / 10\n",
    "criterion_nll = nn.NLLLoss(weight=torch.tensor(inverse_frequencies).to(device))\n",
    "criterion_lovasz = Lovasz_softmax(ignore=0, from_logits=False)\n",
    "\n",
    "#For Waymo\n",
    "inverse_frequencies_waymo = [1.0 / (f + epsilon_w) for f in frequencies_waymo]\n",
    "inverse_frequencies_waymo[0] = min(inverse_frequencies_waymo) / 10\n",
    "criterion_nll_waymo = nn.NLLLoss(weight=torch.tensor(inverse_frequencies_waymo).to(device))\n",
    "criterion_lovasz_waymo = Lovasz_softmax(ignore=0, from_logits=False)\n",
    "\n",
    "# Model, optimizer, and scheduler setup\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay)\n",
    "\n",
    "# Warmup scheduler for initial epochs\n",
    "def warmup_lr_scheduler(optimizer, warmup_epochs, initial_lr):\n",
    "    def lr_lambda(epoch):\n",
    "        return epoch / warmup_epochs if epoch < warmup_epochs else 1\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "warmup_scheduler = warmup_lr_scheduler(optimizer, warmup_epochs, learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    if epoch < warmup_epochs:\n",
    "        warmup_scheduler.step()\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    for i, (batchk, batchw) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "\n",
    "        imagek, maskk = batchk\n",
    "        imagew, maskw = batchw\n",
    "        imagekw = torch.cat((imagek,imagew), dim=0)\n",
    "\n",
    "        maskk = maskk.to(device)\n",
    "        maskw = maskw.to(device)\n",
    "        imagekw = imagekw.to(torch.float32).to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass and loss computation\n",
    "        output1, output2 = model(imagekw)\n",
    "        outputk, outputw = output1[:batch_size], output2[batch_size:]\n",
    "    \n",
    "        loss_kitti = criterion_nll(torch.log(outputk), maskk) + criterion_lovasz(outputk, maskk)\n",
    "        loss_waymo = criterion_nll_waymo(torch.log(outputw), maskw) + criterion_lovasz_waymo(outputw, maskw)\n",
    "\n",
    "        loss = 0.8*loss_kitti + 0.2*loss_waymo\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        break\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{max_epochs}], Training Loss: {running_loss / len(train_dataloader):.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    miou_total_kitti = 0.0\n",
    "    miou_total_waymo = 0.0\n",
    "    batch_results_kitti, batch_results_waymo = [], [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(kvalidation_dataloader):\n",
    "            images, masks = images.to(torch.float32).to(device), masks.to(device)\n",
    "\n",
    "            # Forward pass and predictions\n",
    "            outputs = model(images)[0]\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            # mIoU calculation and class-wise IoU collection\n",
    "            miou = calculate_miou(preds, masks, num_classes=num_classes_kitti, ignore_index=0)\n",
    "            cwiou = calculate_classwise_intersection_union(preds, masks,num_classes=num_classes_kitti)\n",
    "            batch_results_kitti.append(cwiou)\n",
    "\n",
    "            miou_total_kitti += miou\n",
    "\n",
    "        for i, (images, masks) in enumerate(wvalidation_dataloader):\n",
    "            images, masks = images.to(torch.float32).to(device), masks.to(device)\n",
    "\n",
    "            # Forward pass and predictions\n",
    "            outputs = model(images)[1]\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            # mIoU calculation and class-wise IoU collection\n",
    "            miou = calculate_miou(preds, masks, num_classes=num_classes_waymo, ignore_index=0)\n",
    "            cwiou = calculate_classwise_intersection_union(preds, masks,num_classes=num_classes_waymo)\n",
    "            batch_results_waymo.append(cwiou)\n",
    "\n",
    "            miou_total_waymo += miou\n",
    "\n",
    "    # Calculate and display mIoU metrics\n",
    "    print('###################KITTI_START########################')\n",
    "    classwise_iou, mean_iou, total_iou = calculate_final_miou_from_batches(batch_results_kitti, num_classes=num_classes_kitti)\n",
    "    print_miou_kitti(classwise_iou, mean_iou, total_iou)\n",
    "    avg_miou_kitti = miou_total_kitti / len(kvalidation_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{max_epochs}], Validation mIoU Kitti: {avg_miou_kitti:.4f}\")\n",
    "    print('###################KITTI_END##########################')\n",
    "\n",
    "    # Calculate and display mIoU metrics\n",
    "    print('###################WAYMO_START########################')\n",
    "    classwise_iou, mean_iou, total_iou = calculate_final_miou_from_batches(batch_results_waymo, num_classes=num_classes_waymo)\n",
    "    print_miou_waymo(classwise_iou, mean_iou, total_iou)\n",
    "    avg_miou_waymo = miou_total_waymo / len(wvalidation_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{max_epochs}], Validation mIoU Waymo: {avg_miou_waymo:.4f}\")\n",
    "    print('###################WAYMO_END##########################')\n",
    "\n",
    "    # Save model checkpoint\n",
    "    torch.save(model.state_dict(), f'model_state_dict_{epoch}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
